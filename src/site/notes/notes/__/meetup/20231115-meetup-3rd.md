---
{"dg-publish":true,"permalink":"/notes/__/meetup/20231115-meetup-3rd/","noteIcon":"","created":"2023-12-20T00:33:04.000+09:00"}
---


### Time Table


![](https://i.imgur.com/ZkuL7cM.png)


### session 1. 브라우징 코파일럿 RAG(라그라고 하네요) 도입기


- [browsing copilot](https://getliner.com/ko)
    - brower extension
- why
    - 깊게 이야기하지 않고 빠르게 넘어갔어요.
- sourcing system
    - 유튜브는 자막 처리
    - bigquery 이용
    - HTML 파싱 → CPU 부하 → 분리 (파이썬, 성능개선을 위해 다른 언어로 포팅할 계획)
    - chunk 를 나누는 이유
        - context limit
        - not whole
        - 임베딩 범위 축소
    - 청크를 어떻게 쪼개야 하는가 (라이너는 순서대로 분리)
    - 코틀린
    - 임베딩 API 는 OpenAI 사용
    - elasticsearch 로 vectorDB 사용
        - \_id 를 식별하는 값으로 설정 (즉각조회 목적)
    - 하이브리드 검색
        - 키워드 추출은 LLM
        - es scoring 으로 최종 검색
    - 서비스 데이터 맥락 제공 (하이라이팅 데이터 제공)
- challenge
    - chunk size
        - 크고 작음에 따라 트레이드오프 존재
        - 퍼포먼스 & 비용
        - 큼직하게 자르는중
    - manage IO
    - 키워드 잘뽑기
        - 추상 수준이 높아지지 않게 컨트롤
    - evalutation
        - Retrieval
        - OpenAI 업데이트에 따라 모델이 조금씩 변형됨
        - 컨텐츠에 대한 이해
            - multi-vector search
            - 질문(1) → 질문에 대한 추상화된 질문 생성(2) → 1/2 를 함께 검색하면 검색성능이 좋을까? (논문도 있다고 함)
    - Invesment vs Return

개인적인 후기
- RAG 에 대한 개념이 없다보니 무작정 작성해보긴 했다. (내용들을, 발표자료를 공유해줬으면 좋겠다)
- LLM 을 어떻게 활용할 수 있는지에 대해 fine tuning, RAG 가 있다는 사실을 이제야 알게됐다. 아직 분야가 노다지(?)다보니 관심갖고 보면 좋을 것 같다는 생각이 들었다.

참고자료
- https://www.skelterlabs.com/blog/rag-vs-finetuning


### session 2. KafkaStreams 를 이용한 Change log 따라잡기


- 구조 및 배경 설명
    - ITEM MATCHER ←→ PRODUCT 매핑이 필요한 상황
    - 배치/실시간, 변경을 실시간으로 감지하고 싶다.
- problem
    - 공용 플랫폼이다 보니 대충 데이터가 크다.
    - 별도 DB 운영이 어렵다.
    - CDC 로 변경된 상위 노드 데이터를 감지하고 이를 하위 노드에게까지 전파하는게 목적
- problem 기술
- Kafka Streams
    - state store / repartition 의 경우 카프카 토픽으로 쓰여짐
- 질문
    - CDC 데이터는 DB 팀에서 관리해서 어떤 도구를 쓰는지 모름 (디비지움이냐는 질문이었음)
    - flink vs kafka
        - 인프라 구축 필요없어 flink

개인적인 후기
- 외부 발표자료다보니 내부 문제를 깊게 살펴보지 못해서 아쉬웠다.
- 광고 도메인을 부족하다보니 데이터가 어떤식으로 흘러가고, 어떻게 이용되는지 이해하는 데 시간이 다소 소요되었다.
- KafkaStreams 는 이름만 들어봤는데 `이렇게도 사용되는구나` 하고 느꼈다.

### session 3. OLAP 개념과 서비스 소개


- OLAP 고민중
    - 00:00~09:00 까지 고객사가 aggregation 한 결과를 조회할 수 있도록 해당 시간 내 마트테이블을 생성하고 있음
    - S3 → athena 쿼리 → MySQL (발표 막판에 EMR 쓰는거 같음)
    - 데이터 연산이 많다 (약 2800만 로우 테이블)
    - 한정적인 연산 시간
- OLAP Cube / MOLAP, ROLAP, HOLAP
- Redshift
    - MPP Architecture
    - AQUA engine (쿼리 최적화)
    - AWS 에서 처리하고 있어서 GCP/Azure 는 고려안함
- 직접 운영할만한건 없을까?
    - druid, kylin, clickhouse, pinot
    - clickhouse
        - Shared-Nothing Architecture
        - Cons
            - 단일 솔루션이라 확장이 어려움. 스펙 올려서 마이그레이션 해라 라는 식의 대응
            - 실시간에 보장하지 못한다

개인적인 후기
  - 스피커도 말했듯이 이런 선택지에 놓였는데 너희들(비스피커)은 비슷한 경험을 했니? 를 목적의 발표로 느껴짐
  - 다방면으로 다양한 서비스를 비교했구나
  - 나중에 어떤 OLAP 을 선택했는지 궁금하다.
