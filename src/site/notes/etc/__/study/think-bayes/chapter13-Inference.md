---
{"dg-publish":true,"permalink":"/etc/__/study/think-bayes/chapter13-Inference/","dgPassFrontmatter":true,"noteIcon":"","created":"2023-12-20T00:33:04.000+09:00"}
---

#think-bayes #probability #study

---

# Inference (ì¶”ë¡ )

> p-value ëŠ” ì–´ì©Œê³ ?

- ì¼ë°˜ì  ì¶”ë¡  ë°©ì‹ê³¼ ë² ì´ì§€ì•ˆ ì¶”ë¡  ë°©ì‹ì„ ë¹„êµí•  ë•Œë§ˆë‹¤ ê°€ì¥ ìì£¼ ë‚˜ì˜¤ëŠ” ì§ˆë¬¸ ì¤‘ í•˜ë‚˜
- ê³ ì „ì  í†µê³„ ì¶”ë¡ 
	- student t-ê²€ì • -> p-value
	- ì˜ê°€ì„¤ ìœ ì˜ì„± ê²€ì • (null hypothesis significance testing)
- bayesian inference
	- ë‘ ì§‘ë‹¨ ê°„ ì°¨ì´ì— ëŒ€í•œ posterior ë¶„í¬ ê³„ì‚°
	- ìœ„ ë¶„í¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ
		- ê°€ì¥ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì°¨ì´ì˜ í¬ê¸°
		- ì‹¤ì œ ì°¨ì´ë¥¼ í¬í•¨í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê°„ê²©
		- ìš°ì›” í™•ë¥  (probability of superiority) ë˜ëŠ” ì°¨ì´ê°€ ì„ê³„ê°’ì„ ì´ˆê³¼í•  í™•ë¥ 

# Improving Reading Ability

> í•œ êµìœ¡ìëŠ” êµì‹¤ì—ì„œ ìƒˆë¡œìš´ ì§€ì‹œí˜• ì½ê¸° í™œë™ì´ ì´ˆë“±í•™ìƒì˜ ì½ê¸° ëŠ¥ë ¥ í–¥ìƒì— ë„ì›€ì´ ë˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•´ ì‹¤í—˜ì„ ì‹¤ì‹œí–ˆìŠµë‹ˆë‹¤. ê·¸ë…€ëŠ” 21ëª…ì˜ í•™ìƒìœ¼ë¡œ êµ¬ì„±ëœ 3í•™ë…„ í•™ê¸‰ì— 8ì£¼ ë™ì•ˆ ì´ëŸ¬í•œ í™œë™ì„ ë”°ë¥´ë„ë¡ í–ˆìŠµë‹ˆë‹¤. 23ëª…ì˜ 3í•™ë…„ í•™ìƒìœ¼ë¡œ êµ¬ì„±ëœ ëŒ€ì¡°êµ° í•™ê¸‰ì€ í™œë™ ì—†ì´ ë™ì¼í•œ ì»¤ë¦¬í˜ëŸ¼ì„ ë”°ëìŠµë‹ˆë‹¤. 8ì£¼ê°€ ëë‚  ë¬´ë µ, ëª¨ë“  í•™ìƒë“¤ì€ ì¹˜ë£Œê°€ ê°œì„ í•˜ë„ë¡ ì„¤ê³„ëœ ì½ê¸° ëŠ¥ë ¥ì˜ ì¸¡ë©´ì„ ì¸¡ì •í•˜ëŠ” ì½ê¸° ëŠ¥ë ¥ ì •ë„(DRP) ì‹œí—˜ì„ ì¹˜ë €ìŠµë‹ˆë‹¤.

```python
import pandas as pd

df = pd.read_csv('drp_scores.csv', skiprows=21, delimiter='\t')
df.head(3)
  Treatment  Response
0   Treated        24
1   Treated        43
2   Treated        58
```

```python
# Treated ì™€ Control ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ì–´ë³´ì
grouped = df.groupby('Treatment')
responses = {}

for name, group in grouped:
    responses[name] = group['Response']

# ë‘ ì§‘ë‹¨ì˜ ì ìˆ˜ì˜ CDF ë¶„í¬ë¥¼ ê·¸ë¦¬ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.
from empiricaldist import Cdf
from utils import decorate

for name, response in responses.items():
    cdf = Cdf.from_seq(response)
    cdf.plot(label=name)
    
decorate(xlabel='Score', 
         ylabel='CDF',
         title='Distributions of test scores')
```

![](https://i.imgur.com/CIohIxk.png)

- **ê²¹ì¹˜ëŠ” ë¶€ë¶„ì€ ìˆìœ¼ë‚˜ Treated (ì‹¤í—˜êµ°) ê°€ ì ìˆ˜ê°€ ë†’ë‹¤.**
- ë‘ ì§‘ë‹¨ ëª¨ë‘ ì™„ë²½í•œ ì •ê·œë¶„í¬ëŠ” ì´ë£¨ê³  ìˆì§€ ì•Šì§€ë§Œ ì •ê·œë¶„í¬ë¥¼ ì‚¬ìš©í•´ë„ ë¬´ë°©
	- *CDF ëª¨ì–‘ì´ S ìë¥¼ ë”°ë¥´ê³  ìˆë‹¤. ì´ëŠ” ì •ê·œë¶„í¬ì˜ CDF ì™€ ìœ ì‚¬í•˜ë¯€ë¡œ ì €ìëŠ” ì •ê·œë¶„í¬ì„ì„ ë³´ì—¬ì£¼ì§€ ì•Šê³  ë¹ ë¥´ê²Œ ë„˜ì–´ê°„ ë“¯ í•˜ë‹¤.*
- í•™ìƒ ëª¨ì§‘ë‹¨ì—ì„œ ì ìˆ˜ì˜ ë¶„í¬ëŠ” ì •ê·œë¶„í¬ë¥¼ ì´ë£¨ê³  ì•„ì§ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ëŠ” ëª¨ë¥¸ë‹¤ê³  ê°€ì •
	- mu, sigma
	- **ì´ ê°’ì„ ì¶”ì •(estimate)í•˜ê¸° ìœ„í•´ bayesian update**

# Estimating Parameters (ë§¤ê°œë³€ìˆ˜ ì¶”ì •)

- parameter ì˜ prior ë¶„í¬ê°€ í•„ìš”
	- **ë‘ ê°œ param -> joint distribution**
- ì ˆì°¨
	- marginal distribution ê³„ì‚°
	- marginal distribution ê°„ ì™¸ì ì„ ì´ìš©í•´ joint distribution ê³„ì‚°

mu & sigma uniform ì´ë¼ ê°€ì •í•œë‹¤.

```python
from empiricaldist import Pmf

def make_uniform(qs, name=None, **options):
    """Make a Pmf that represents a uniform distribution."""
    pmf = Pmf(1.0, qs, **options)
    pmf.normalize()
    if name:
        pmf.index.name = name
    return pmf

import numpy as np

qs = np.linspace(20, 80, num=101) #ìƒí•œê³¼ í•˜í•œì„ ì„¤ì •(20, 80)
prior_mu = make_uniform(qs, name='mean')

qs = np.linspace(5, 30, num=101) #ë§ˆì°¬ê°€ì§€ë¡œ ìƒ/í•˜í•œ ì„¤ì •(5, 30)
prior_sigma = make_uniform(qs, name='std')

from utils import make_joint # ì´ì „ì— ì‚´í´ë³¸ joint ë¶„í¬ ìƒì„± í•¨ìˆ˜ (retrun dataframe)

prior = make_joint(prior_mu, prior_sigma)

data = responses['Control'] # ëŒ€ì¡°êµ° ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ìƒì„±í•œë‹¤.
data.shape
(23, )
```

# Likelihood (ê°€ëŠ¥ë„)
```python
# mu & sigma ê°’ì˜ ê° ìŒì— ëŒ€í•œ ì ìˆ˜ë³„ í™•ë¥ ì„ ì‚´í´ë³¸ë‹¤.
mu_mesh, sigma_mesh, data_mesh = np.meshgrid(
    prior.columns, prior.index, data) # x: mu, y: sigma, z: data

mu_mesh.shape
(101, 101, 23)

from scipy.stats import norm

# probability density
densities = norm(mu_mesh, sigma_mesh).pdf(data_mesh)
densities.shape
(101, 101, 23)

from utils import normalize

# axis=2 ê°’ -> likelihood
likelihood = densities.prod(axis=2)
likelihood.shape
(101, 101)

# bayesian update
posterior = prior * likelihood
normalize(posterior)
posterior.shape
(101, 101)
```

```python
def update_norm(prior, data):
    """Update the prior based on data."""
    mu_mesh, sigma_mesh, data_mesh = np.meshgrid(
        prior.columns, prior.index, data)
    
    densities = norm(mu_mesh, sigma_mesh).pdf(data_mesh)
    likelihood = densities.prod(axis=2)
    
    posterior = prior * likelihood
    normalize(posterior)

    return posterior

# Control
data = responses['Control']
posterior_control = update_norm(prior, data)

# Treated
data = responses['Treated']
posterior_treated = update_norm(prior, data)
```

![](https://i.imgur.com/Ctyx6Ow.png)

- ì‹¤í—˜ì´ ì°¨ì´ë¥¼ ë§Œë“¤ì–´ëƒˆë‹¤ë©´ -> ì‹¤í—˜ìœ¼ë¡œ ì¸í•´ í‰ê·  ì ìˆ˜ê°€ ì˜¬ë¼ê°€ê³  ë¶„í¬ ì •ë„(spread) ë¥¼ ë‚®ì¶°ì¤¬ë‹¤ ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤.
- mu & sigma ì˜ marginal ë¶„í¬ë¥¼ ì‚´í´ë³´ë©´ ë³´ë‹¤ ëª…í™•íˆ ì•Œ ìˆ˜ ìˆë‹¤(ê³  í•œë‹¤)

# Posterior Marginal Distributions

```python
from utils import marginal

pmf_mean_control = marginal(posterior_control, 0)
pmf_mean_treated = marginal(posterior_treated, 0)
```

![](https://i.imgur.com/ZrJQt4K.png)

- posterior ì–‘ tail ìª½ì´ ëª¨ë‘ 0 -> prior ìƒ/í•˜í•œê°’ ë²”ìœ„ê°€ ì¶©ë¶„í•¨ì„ ì˜ë¯¸

```python
Pmf.prob_gt(pmf_mean_treated, pmf_mean_control)
0.980479025187326
```

# Distribution of Differences (ì°¨ì´ì˜ ë¶„í¬)

ì§‘ë‹¨ ê°„ ì°¨ì´ë¥¼ ìˆ˜ëŸ‰í™”í•˜ê³ ì sub_dist() ë¥¼ ì´ìš©í•´ ì°¨ì´ ë¶„í¬ë¥¼ ê³„ì‚°í•œë‹¤.
```python
pmf_diff = Pmf.sub_dist(pmf_mean_treated, pmf_mean_control)

len(pmf_mean_treated), len(pmf_mean_control), len(pmf_diff)
(101, 101, 879)
```

![](https://i.imgur.com/iBTeRlD.png)

ì œì•½ì¡°ê±´(*ì™¸ì  ì‹œ ë°ì´í„°ì˜ í¬ê¸°ê°€ ë§ì´ ì»¤ì§„ë‹¤ & pmf ë¥¼ ë„ì‹í™” í•  ë•Œ ì§€ì €ë¶„í•˜ë‹¤*)ì„ í•´ì†Œí•  ë‘ ê°€ì§€ ë°©ë²• ì¤‘ í•˜ë‚˜ëŠ” CDF ë¥¼ ê·¸ë¦¬ëŠ” ê²ƒ
![](https://i.imgur.com/EftqbMb.png)

ë‹¤ë¥¸ ë°©ë²•ì€ KDE ë¥¼ ì´ìš©í•´ PDF ì˜ smooth approximation ì„ êµ¬í•˜ëŠ” ê²ƒ
```python
from scipy.stats import gaussian_kde

def kde_from_pmf(pmf, n=101):
    """Make a kernel density estimate for a PMF."""
    kde = gaussian_kde(pmf.qs, weights=pmf.ps)
    qs = np.linspace(pmf.qs.min(), pmf.qs.max(), n)
    ps = kde.evaluate(qs)
    pmf = Pmf(ps, qs)
    pmf.normalize()
    return pmf

kde_diff = kde_from_pmf(pmf_diff)
# kde_diff plot
```

![](https://i.imgur.com/6rXWxDN.png)

```python
pmf_diff.mean()
9.954413088940848

pmf_diff.credible_interval(0.9)
array([ 2.4, 17.4])
```

- ì‹œí—˜ ì ìˆ˜ í‰ê· ì´ 45ì  ì¼ ë•Œ ë¶„í¬ì˜ í‰ê· ì€ ì•½ 10ì ì´ë¯€ë¡œ ìƒë‹¹í•œ íš¨ê³¼ë¥¼ ê±°ë‘ì—ˆë‹¤ ë³¼ ìˆ˜ ìˆìŒ
	- **45ì ì€ ì–´ë””ì„œ ë‚˜ì˜¨ ìˆ«ìì¸ê°€ìš”? ì£¼ì–´ì§„ ë°ì´í„°ì˜ ì‹œí—˜ì ìˆ˜ í‰ê· ì´ ëŒ€ëµ 46 ì´ê¸° ë•Œë¬¸ì— around 45 ë¼ê³  ì´ì•¼ê¸°í•œê±´ê°€ìš”?**
- credible interval ì— ë”°ë¥´ë©´ 2 -> 17.4 ë¥¼ ì˜¬ë¦¬ëŠ” íš¨ê³¼ê°€ ìˆì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆìŒ

# Using Summary Statistics
- ë§Œì•½ ìš°ë¦¬ê°€ ë” í° ë°ì´í„°ë¥¼ ë‹¤ë£¬ë‹¤ë©´..
	- 3ì°¨ì› ë°°ì—´ì„ ê³„ì‚°í•˜ë©´ êµ‰ì¥íˆ ì˜¤ë˜ê±¸ë¦´ ìˆ˜ ìˆìŒ
	- likelihood ê°€ êµ‰ì¥íˆ ì‘ì•„ì§
- ì´ëŸ° ê²½ìš° summary ê°’ì„ êµ¬í•˜ê³  ì´ì˜ likelihood ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•
	- **í•œ ì§‘ë‹¨ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•˜ë©´ likelihood ê°’ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŒ**

```python
# ëª¨í‰ê·  mu ì™€ sigma ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  í•´ë³´ì
mu = 42
sigma = 17

# ì„ì˜ë¡œ n = 20 ì¸ í‘œë³¸ì„ ì¶”ì¶œí–ˆë‹¤ê³  í•˜ì. í‘œë³¸ì˜ í‰ê· ì€ m, í‘œë³¸ì˜ í‘œì¤€í¸ì°¨: s
n = 20
m = 41
s = 18
```

mathematical statistics (ìˆ˜ë¦¬í†µê³„) ì„ ì´ìš©í•´ likelhood ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŒ
1. ğœ‡ ë° ğœ ê°€ ì£¼ì–´ì§€ë©´ m ì˜ ë¶„í¬ëŠ” íŒŒë¼ë¯¸í„° $\mu$ and $\sigma/\sqrt{n}$ ì™€ í•¨ê»˜ ì •ê·œ ë¶„í¬ì´ë‹¤.
2. ğ‘ ì˜ ë¶„í¬ëŠ” ë” ë³µì¡í•˜ì§€ë§Œ ğ‘¡=ğ‘›ğ‘ 2/ğœ2 ë³€í™˜ì„ ê³„ì‚°í•˜ë©´ ğ‘¡ì˜ ë¶„í¬ëŠ” ë§¤ê°œ ë³€ìˆ˜ ğ‘›-1 ì„ ì‚¬ìš©í•œ ì¹´ì´ì œê³±ë¶„í¬ê°€ ëœë‹¤.
3. Basu ì •ë¦¬ì— ë”°ë¥´ë©´ m ì™€ s ëŠ” ë…ë¦½ì ì´ë‹¤.

```python
dist_m = norm(mu, sigma/np.sqrt(n)) # í‰ê· ì˜ í‘œë³¸ ë¶„í¬ (sampling distribution of mean)
like1 = dist_m.pdf(m)
like1
0.10137915138497372

t = n * s**2 / sigma**2
t
22.422145328719722

from scipy.stats import chi2

dist_s = chi2(n-1) # ì¹´ì´ì œê³±ë¶„í¬

like2 = dist_s.pdf(t)
like2
0.04736427909437004

like = like1 * like2 # basu ì •ë¦¬ì— ë”°ë¦„
like
0.004801750420548287
```

# Update with Summary Statictics
```python
summary = {}

for name, response in responses.items():
    summary[name] = len(response), response.mean(), response.std()
    
summary
{'Control': (23, 41.52173913043478, 17.148733229699484), 'Treated': (21, 51.476190476190474, 11.00735684721381)}
```

Control ì˜ summary ë¥¼ êµ¬í•œë‹¤.
```python
n, m, s = summary['Control']
```

mu & sigma ê°€ì„¤ê°’ì„ ì™¸ì ì„ ì´ìš©í•´ meshgrid ë¥¼ ìƒì„±í•œë‹¤.
```python
mus, sigmas = np.meshgrid(prior.columns, prior.index)
mus.shape
(101, 101)
```

mu & sigma ì˜ likelihood ë¥¼ ê³„ì‚°í•˜ê³  update í•´ë³¸ë‹¤.
```python
like1 = norm(mus, sigmas/np.sqrt(n)).pdf(m)
like1.shape

ts = n * s**2 / sigmas**2
like2 = chi2(n-1).pdf(ts)
like2.shape

posterior_control2 = prior * like1 * like2
normalize(posterior_control2)

# ìœ„ ê³¼ì •ì„ í•˜ë‚˜ë¡œ ë¬¶ì€ í•¨ìˆ˜
def update_norm_summary(prior, data):
    """Update a normal distribution using summary statistics."""
    n, m, s = data
    mu_mesh, sigma_mesh = np.meshgrid(prior.columns, prior.index)
    
    like1 = norm(mu_mesh, sigma_mesh/np.sqrt(n)).pdf(m)
    like2 = chi2(n-1).pdf(n * s**2 / sigma_mesh**2)
    
    posterior = prior * like1 * like2
    normalize(posterior)
    
    return posterior

# ìœ„ í•¨ìˆ˜ë¥¼ ì´ìš©í•´ Treated ê·¸ë£¹ë„ update í•œë‹¤.
data = summary['Treated']
posterior_treated2 = update_norm_summary(prior, data)
```

![](https://i.imgur.com/0J42IUU.png)

ì´ëŠ” ì•ì„œ ê³„ì‚°í–ˆë˜ ê²ƒê³¼ ë¹„ìŠ·í•´ë³´ì´ì§€ë§Œ marginal distribution ì„ êµ¬í•´ë³´ë©´ ì™„ì „íˆ ê°™ì§€ëŠ” ì•Šì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# Posterior Marginal Distributions

```python
from utils import marginal

pmf_mean_control2 = marginal(posterior_control2, 0)
pmf_mean_treated2 = marginal(posterior_treated2, 0)
```

![](https://i.imgur.com/oAdLXNe.png)


```python
Pmf.prob_gt(pmf_mean_treated, pmf_mean_control)
0.980479025187326
```

- summary ê¸°ë°˜ posterior ê°€ ì§§ê³  ë” ë„“ì€ í˜•íƒœ
	- **ì´ëŠ” ë°ì´í„° ë¶„í¬ê°€ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ê³  ê°€ì •í•˜ê³  summary ê°’ì„ ì‚¬ìš©í•´ ê°±ì‹ í–ˆê¸° ë•Œë¬¸**
	- ì´ ê°€ì •ì€ ë¶ˆì•ˆì •í•˜ê¸° ë•Œë¬¸ì— summary ë¥¼ ì‚¬ìš©í•˜ë©´ ì¼ë¶€ ì •ë³´ë¥¼ ì†ì‹¤í•  ìˆ˜ ìˆìŒ
- ì •ë³´ê°€ ì ì–´ì§€ë©´ parameter ì— ëŒ€í•œ í™•ì‹ (certain)ì´ ì¤„ì–´ë“¤ ìˆ˜ ë°–ì— ì—†ìŒ